# UI-Vision: A Desktop-centric GUI Benchmark for Visual Perception and Interaction

[![arXiv](https://img.shields.io/badge/arXiv-2503.15661-b31b1b.svg)](https://arxiv.org/abs/2503.15661)
[![Website](https://img.shields.io/badge/Website-UI--Vision-blue)](https://uivision.github.io/)
[![Dataset](https://img.shields.io/badge/Dataset-Coming%20Soon-green)](#)

## ðŸ“¢ News
- **[Coming Soon]** Dataset and code release
- **[19 March 2024]** Project website is live at [uivision.github.io](https://uivision.github.io/)
- **[19 March 2024]** UI-Vision paper is available on [arXiv](https://arxiv.org/abs/2503.15661) ðŸ”¥ ðŸ”¥ 


## Introduction
UI-Vision is a comprehensive, license-permissive benchmark for offline, fine-grained evaluation of computer use agents in real-world desktop environments across 83 software applications spanning 6 categories. The benchmark includes:

- Dense, high-quality annotations of human demonstrations
- Bounding boxes, UI labels, and action trajectories across 83 software applications
- Three fine-to-coarse grained tasks:
  - Element Grounding
  - Layout Grounding  
  - Action Prediction

The benchmark aims to advance the development of more capable agents for real-world desktop tasks.

## Citation

If you find UI-Vision useful in your research, please consider citing our paper:

```bibtex
@misc{nayak2025uivisiondesktopcentricguibenchmark,
  title={UI-Vision: A Desktop-centric GUI Benchmark for Visual Perception and Interaction},
  author={Shravan Nayak and Xiangru Jian and Kevin Qinghong Lin and Juan A. Rodriguez and
  Montek Kalsi and Rabiul Awal and Nicolas Chapados and M. Tamer Ã–zsu and
  Aishwarya Agrawal and David Vazquez and Christopher Pal and Perouz Taslakian and
  Spandana Gella and Sai Rajeswar},
  year={2025},
  eprint={2503.15661},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2503.15661},
}
```